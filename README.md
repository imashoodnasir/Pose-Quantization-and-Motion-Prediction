# Pose Quantization and Motion Prediction using Deep Learning

This repository implements a **Deep Learning-based Framework for Music-Synchronized Dance Choreography**, featuring **Pose Quantization and Motion Prediction**. The system utilizes **Vision Transformers (ViT)**, **Graph Convolutional Networks (GCN)**, **K-means Clustering**, and **Differential Evolution Optimization** to generate synchronized dance choreography based on music.
  
## **ğŸ“Œ Features**
âœ… **SE-ViT (Vision Transformer with Squeeze & Excitation)**  
âœ… **GCN-MHW (Graph Convolutional Network with Mexican Hat Wavelet)**  
âœ… **Pose Quantization (K-means & VQ-VAE)**  
âœ… **Music Synchronization with Beat Alignment**  
âœ… **Differential Evolution Optimization for Loss Minimization**  
âœ… **Trained on AIST++ Dataset**  

---

## **ğŸ“‚ Project Structure**
```
Pose-Quantization-and-Motion-Prediction/
â”‚â”€â”€ data_preprocessing.py         # Data loading and preprocessing (AIST++)
â”‚â”€â”€ se_vit.py                     # SE-ViT for pose feature extraction
â”‚â”€â”€ gcn_mhw.py                    # GCN-MHW for motion prediction
â”‚â”€â”€ pose_quantization.py          # K-Means and VQ-VAE-based pose quantization
â”‚â”€â”€ music_synchronization.py      # Music synchronization loss function
â”‚â”€â”€ differential_evolution.py     # Optimization using Differential Evolution
â”‚â”€â”€ train.py                      # Model training script
â”‚â”€â”€ test.py                       # Model inference and testing
â”‚â”€â”€ requirements.txt              # Dependencies
â”‚â”€â”€ README.md                     # Documentation
```

---

## **ğŸš€ Installation**
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/imashoodnasir/Pose-Quantization-and-Motion-Prediction.git
cd Pose-Quantization-and-Motion-Prediction
```

### **2ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

---

## **ğŸ“Š Dataset**
- The model is trained on the **AIST++ dataset**, a large-scale 3D human dance dataset.
- **Download AIST++**: [AIST++ Dataset](https://google.github.io/aistplusplus_dataset/)

---

## **ğŸ›  Usage**
### **1ï¸âƒ£ Preprocess Dataset**
```bash
python data_preprocessing.py
```

### **2ï¸âƒ£ Train Model**
```bash
python train.py
```

### **3ï¸âƒ£ Test Model**
```bash
python test.py
```

---

## **ğŸ“ Model Components**
### **1ï¸âƒ£ SE-ViT (Vision Transformer)**
- Extracts **pose features** from dance video frames.
- Uses **Squeeze and Excitation (SE) blocks** for feature recalibration.

### **2ï¸âƒ£ GCN-MHW (Graph Convolutional Network)**
- Converts **pose sequences into graphs**.
- Uses **Mexican Hat Wavelet** for better motion prediction.

### **3ï¸âƒ£ Pose Quantization**
- **K-means clustering** groups poses into representative states.
- **VQ-VAE** (Vector Quantized Variational Autoencoders) discretizes poses.

### **4ï¸âƒ£ Music Synchronization**
- Aligns pose sequences to music beats using a custom **loss function**.
- Optimized using **Differential Evolution (DE)**.

---

## **ğŸ“Š Results**
### **Performance Metrics**
| Model | FID (Kinetic) â†“ | FID (Geometric) â†“ | Motion Diversity â†‘ | Beat Align â†‘ |
|------|-------------|-------------|----------------|-----------|
| **Proposed (log-sigmoid DE)** | **32.78** | **11.37** | **6.89** | **0.257** |
| Baseline (Li Ruilong, 2021) | 35.35 | 12.40 | 5.94 | 0.241 |
| Baseline (Li Jiaman, 2020) | 86.43 | 20.58 | 6.85 | 0.232 |

âœ… **Better motion quality & diversity than existing methods!**

---

## **ğŸ”¬ Research Contributions**
- **Improved Vision Transformers** for pose estimation.
- **Graph-based motion modeling** for dynamic choreography.
- **Music synchronization loss function** with **Differential Evolution**.

---

## **ğŸ’¡ Future Work**
- Extend to **real-time dance generation**.
- Train on **multi-dancer choreography** datasets.
- Integrate **Generative AI (GANs)** for diverse dance movements.

---

## **ğŸ“œ License**
This project is licensed under the **MIT License**.

---

### ğŸŒŸ **If you found this useful, please â­ star the repository!**
